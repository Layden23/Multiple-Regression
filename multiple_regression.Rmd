---
title: "Multiple Regression in R"
author: "Elias Smouni, Joël Ribera Zaragoza"
date: "`r Sys.Date()`"
output:
  rmdformats::readthedown:
    highlight: kate
    toc_depth: 3
    toc_float: true
    collapsed: true
    smooth_scroll: false
    thumbnails: true
    lightbox: true
---


```{r knitr_init, echo=FALSE, cache=FALSE}
library(knitr)
library(rmdformats)

## Global options
options(max.print="75")
opts_chunk$set(echo=T,
	             cache=TRUE,
               prompt=FALSE,
               tidy=TRUE,
               comment=NA,
               message=FALSE,
               warning=FALSE)
opts_knit$set(width=75)
```

## Executive Summary
### Introduction
We were requested to conduct further analysis regarding an earlier data mining operation, in which we used RapidMiner to predict projected sales volumes and subsequent profitability for a shortlist of products considered as possible additions to Blackwell’s selection.

Specifically, we were requested to pick up where we left off, by providing a more elaborate analysis based on the same data. For this analysis, we were asked to explore what, if any, influence the respective product types have on the projecting of sales volumes. Furthermore, we were requested to: 

A.	Predict sales volumes of the following product types:

i)	PC;
ii)	Laptops;
iii)	Netbooks; and
iv)	Smartphones

B.	Assess the impact that services’ and customer satisfaction

The purpose of this summary is to provide the reader with an overview of our key findings and consists appropriately of weighted conclusions. We refer you to the Technical Report that is appended hereto for technical documentation and argumentation.

###	About the data

We implemented our analysis on the same historical data that was used as basis for our projection regarding the envisaged new products. Consequently, the dataset imposes the same limitations as they did in regard of predicting the sales volumes of new products.

The data consisted of 80 observations of 18 attributes in regard of products sold by Blackwell. Our tests show that the most influential attributes in predicting sales were the attributes related to customer sentiment as is evidenced in the technical report.

We note that the data is unevenly distributed and contained a few abnormalities. There were also a few obvious errors from the data collection phase as well as missing data which resulted in the deletion of a number of observations and one attribute, which we would have been glad to avoid considering the sparsity of the dataset.

### Results

We began by analyzing the influence of the attribute “ProductType” on predicting sales volume. We did this through a variance-analysis method, namely ANOVA. The analysis showed that said attribute had no significance toward an inferential analysis of sales. 

This task was a so-called multiple-regression task. We trained the number of supervised-learning algorithms and received the best results with a decision-tree algorithm called Random Forest. Our training yielded a model that inferred the volume from the data with a 92% accuracy.




## Load packages and datasets

```{r load packages}
pacman::p_load(readr,rstudioapi,ggplot2,cowplot,GGally,caret,dplyr,party)
products <- read_csv("datasets/existingproductattributes2017.csv")
newproducts <- read_csv("datasets/newproductattributes2017.csv")
```
## Visualization and data exploration:
```{r visualization}
plotprod <- products[, c(3:11, 13:18)]

for (i in names(plotprod[, -which(names(plotprod) == "Volume")])) {
 print(ggplot(data = plotprod,
              aes_string(x=i, y = plotprod$Volume))
       + geom_jitter(color = "darkred")
       + ylab("Volume")
 )
}
```

We can infer the following already from the visual exploration of the dataset:

i) x5StarReviews has a suspiciously strong positive correlation with Volume;
ii) x4StarReviews has a very strong positive correlation with Volume;
iii) all StarReviews are positively correlated with Volume, even 1 and 2 starreviews, which are generally considered as expressions of negative customer sentiment. This observation suggests that it is the number of reviews rather than the quality of the same that is related to Volume.
iv) Attributes relating to physical or financial aspects of the products are largely irrelevant for the purposes of inferential statistics


## Data preprocessing
```{r duplicates}
#Check duplicated rows
sum(duplicated(products[,-which(names(products) %in% c("ProductNum","Price"))]))
#6 rows from the extended warranty are duplicated, so we'll remove them (but if we search manually we can see that here are 7 of them) 
products <- products[-c(35:41),]
```

```{r NAs and outliers}
#Check NA
any(is.na(products))
for (i in c(1:ncol(products))){
  print(paste(i,any(is.na(products[,i]))))
}
#There are missing values in the 12 column, which is "BestSellersRank". 
#There are 15 missing values in Best Sellers Rank attribute, so we'll remove it.
products <- products[,-which(names(products) %in% "BestSellersRank")]
#Check outliers
boxplot(products$Volume)
#Cleaning outliers
products <- filter(products, 
                   products$Volume < 7000)
```
```{r anova test}
anova_test <- aov(Volume ~ ProductType, data = products)
summary(anova_test)
```
The PValue is too big, so our categorical variables have no relation between the dependent variable.
## Feature Selection
```{r}
ProductType <- as.vector(products$ProductType)
products <- products[,-which(colnames(products) %in% "ProductType")]
#Correlation Matrix
corr_products <- cor(products)
#Colinearity:
findCorrelation(x = corr_products, cutoff = 0.80, names = T)


pairwiseCor <- function(dataframe){
  pairs <- combn(names(dataframe), 2, simplify=FALSE)
  df <- data.frame(Vairable1=rep(0,length(pairs)), Variable2=rep(0,length(pairs)),
                   AbsCor=rep(0,length(pairs)), Cor=rep(0,length(pairs)))
  for(i in 1:length(pairs)){
    df[i,1] <- pairs[[i]][1]
    df[i,2] <- pairs[[i]][2]
    df[i,3] <- round(abs(cor(dataframe[,pairs[[i]][1]], dataframe[,pairs[[i]][2]])),4)
    df[i,4] <- round(cor(dataframe[,pairs[[i]][1]], dataframe[,pairs[[i]][2]]),4)
  }
  pairwiseCorDF <- df
  pairwiseCorDF <- pairwiseCorDF[order(pairwiseCorDF$AbsCor, decreasing=TRUE),]
  row.names(pairwiseCorDF) <- 1:length(pairs)
  pairwiseCorDF <<- pairwiseCorDF
  pairwiseCorDF
}
#x5StarReviews has perfect correlation, and we'll remove it. There's also colinearity between x4StarReviews and x3StarReviews, so we'll remove x3StarReviews. We do the same for x2StarReviews and x1StarReviews.
pairwiseCor(products)
```

```{r}
decisiontree <- ctree(Volume~.,data = 
                        products[,-which(colnames(products) %in% c("x5StarReviews","x3StarReviews", "x1StarReviews"))], 
                      controls = ctree_control(maxdepth = 3))
plot(decisiontree)
```

```{r}
lm_model <- train(Volume~x4StarReviews + x3StarReviews + x2StarReviews + x1StarReviews,
                  products, method = "lm")
summary(lm_model)$coefficients
products$"Avg_WghtStar" <-  summary(lm_model)$coefficients[2]*products$x4StarReviews + 
  summary(lm_model)$coefficients[3]*products$x3StarReviews + 
  summary(lm_model)$coefficients[4]*products$x2StarReviews + 
  summary(lm_model)$coefficients[5]*products$x1StarReviews
```
```{r}
#Decision Tree
avg_decisiontree <- ctree(Volume~.,data = 
                        products[,-which(colnames(products) %in% c("x5StarReviews",
                                                                   "x4StarReviews",
                                                                   "x3StarReviews",
                                                                   "x2StarReviews",
                                                                   "x1StarReviews"))], 
                      controls = ctree_control(maxdepth = 3))
plot(avg_decisiontree)
```

## Modeling
```{r models}
 #Cross validation:
set.seed(69)
indexing <- createDataPartition(products$Volume, p = 0.75, list = F)
trainSet <- products[indexing,]
testSet <- products[-indexing,]

form <- c("Volume ~ x4StarReviews + PositiveServiceReview",
             "Volume ~ Avg_WghtStar + PositiveServiceReview")
models <- c("rf","knn", "svmLinear", "svmRadial","glm")
combined <- c()
cnames <- vector()
for (i in form){
  for (j in models) {
    model <- train(formula(i), data = trainSet, method = j, tuneLength = 3, metric = "MAE")
    predictions <- predict(model, testSet)
    results <- postResample(predictions, testSet$Volume)
    combined <- cbind(results, combined)
    cnames <- c(paste(i,j),cnames)
  }
}
colnames(combined) <-cnames
min(combined[3,] )
kable(combined)
#Best model for MAE is rf with variables= Avg_WghtStar and PositiveServiceReview
```

```{r rf model}
#We create the new avg_wght star variable
newproducts$"Avg_WghtStar" <-  summary(lm_model)$coefficients[2]*newproducts$x4StarReviews + 
  summary(lm_model)$coefficients[3]*newproducts$x3StarReviews + 
  summary(lm_model)$coefficients[4]*newproducts$x2StarReviews + 
  summary(lm_model)$coefficients[5]*newproducts$x1StarReviews

rf_model <- train(Volume ~ Avg_WghtStar + PositiveServiceReview, 
                  trainSet, tuneLength = 3, metric = "MAE")
newproducts$Volume <- predict(rf_model,newproducts)
```
```{r errors}
products$Volume[products$Volume == 0] <- 1
Volume <- as.numeric(products$Volume)
ex_preds <- as.numeric(predict(rf_model,products))
ae_errors <- as.numeric(abs(ex_preds - products$Volume))
re_errors <- as.numeric(ae_errors/products$Volume)
errors_df <- as.data.frame(cbind(Volume,ex_preds,ae_errors,re_errors))
errors_df$ProductType <- ProductType
errors_df$ProductNum <- products$ProductNum

ggplot(errors_df, aes(x = Volume, y = re_errors, color = ProductType)) + geom_jitter() + ylab("Relative error") + ggtitle("Relative error vs Volume")

ggplot(errors_df, aes(x = Volume, y = ae_errors, color = ProductType)) + geom_jitter() + ylab("Absolute error") + ggtitle("Absolute error vs Volume")

ccols <- c("volume"="#f04546","pred"="#3591d1")
ggplot(errors_df, aes()) +geom_jitter(aes(x=ProductNum, y = ex_preds, color = "pred")) + geom_jitter(aes(x=ProductNum, y = Volume, color = "volume" )) +
  geom_smooth(aes(x=ProductNum, y = ex_preds, color = "pred"),method = "loess", 
              se = F) +
  geom_smooth(aes(x=ProductNum, y = Volume, color = "volume"),method = "loess",
              se = F) + ylab("Volume")

```


```{r}
filtered <- newproducts[which(newproducts$ProductType == "PC"|newproducts$ProductType == "Laptop"|
                    newproducts$ProductType == "Netbook"|
                    newproducts$ProductType == "Smartphone"), ]
finalresults <- filtered[,which(colnames(filtered) %in% c("ProductType","ProductNum","Volume"))]
finalresults$Volume <- round(finalresults$Volume,0)
finalresults$Volume <- as.integer(finalresults$Volume)
kable(finalresults, caption = "Volume of the new products")
```


